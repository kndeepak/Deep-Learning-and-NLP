# Deeplearning
Deeplearning with Tensorflow and Keras

ANN

1. Basic building blocks of Neural Network<br>
2. Perceptron<br>
3. Neurons<br>
4. Hidden Layers<br>
5. Linear regression with Neural Networks<br>
6. Logistic regression with Neural Networks<br>
6. No Linear Activation Function<br>
7. tanh, step, logit, relu, elu<br>
8. Back propagation<br>
9. Vanishing and Exploding gradient descent<br>
10. Ways to avoid Vanishing and Exploding gradient descent<br>
11. How to mitigate over fitting ?<br>
12. Tensorflow - Keras practical<br>

CNN

1. Parameter explotion in image recognition
2. Convolution layer - kernel , filter, Stride, Padding, feature map
3. Pooling Layer - max, min, average
4. CNN architecture
5. Keras implementation
6. Image recognition in comparison with Basis NN and CNN
7. Advanced Deep CNN
8. Pre Trained Models
9. Transfer Learning - Resnet50
10. Image Agumentation
11. Tensor board
12. Opencv, Yolo3
13. Sample Hackathon

RNN 

1. Neural Network so far can only know what was passed in current time
2. What if we want to remember last output to predict the future if it is a sequence data
3. Neuron with memory
4. RNN architecture
5. Back Propagation Through Time (BPTT)
6. Problem with BPTT
7. Vanishing and Exploding gradient descent
8. Truncated BPTT
9. LSTM
10. LSTM Architecture
11. Keras LSTM implementation



References: 
https://github.com/omerbsezer/LSTM_RNN_Tutorials_with_Demo#SampleStock
https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.1-text-generation-with-lstm.ipynb
https://github.com/dipanjanS/nlp_workshop_odsc19
https://github.com/buomsoo-kim/Easy-deep-learning-with-Keras
